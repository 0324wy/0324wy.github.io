<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Yan Wang</title>
    <link>https://0324wy.github.io/projects/</link>
      <atom:link href="https://0324wy.github.io/projects/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 22 Mar 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://0324wy.github.io/media/icon_hu85c61bd5867a769d7d24d0bf9f947657_254979_512x512_fill_lanczos_center_3.png</url>
      <title>Projects</title>
      <link>https://0324wy.github.io/projects/</link>
    </image>
    
    <item>
      <title>Designed and Built a Deep Learning Library Called Needle</title>
      <link>https://0324wy.github.io/projects/needle/</link>
      <pubDate>Wed, 22 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://0324wy.github.io/projects/needle/</guid>
      <description>&lt;p style=&#34;text-align: justify;&#34;&gt;Completed an online course on deep learning systems offered by CMU in order to delve into the internals of PyTorch and TensorFlow, and understand how they function at a fundamental level.&lt;/p&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;Designed and built a deep learning library called Needle, capable of efficient GPU-based operations, automatic differentiation of all implemented functions, and the necessary modules to support parameterized layers, loss functions, data loaders, and optimizers.&lt;/p&gt;
&lt;h2 id=&#34;project-0&#34;&gt;Project 0&lt;/h2&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;Build a basic softmax regression algorithm, plus a simple two-layer neural network. Create these implementations both in native Python (using the numpy library), and (for softmax regression) in native C/C++.&lt;/p&gt;
&lt;p&gt;✅ A basic &lt;code&gt;add&lt;/code&gt; function&lt;/p&gt;
&lt;p&gt;✅ Loading MNIST data:  &lt;code&gt;parse_mnist&lt;/code&gt; function&lt;/p&gt;
&lt;p&gt;✅Softmax loss: &lt;code&gt;softmax_loss&lt;/code&gt; function&lt;/p&gt;
&lt;p&gt;✅Stochastic gradient descent for softmax regression&lt;/p&gt;
&lt;p&gt;✅SGD for a two-layer neural network&lt;/p&gt;
&lt;p&gt;✅Softmax regression in C++&lt;/p&gt;
&lt;h2 id=&#34;project-1&#34;&gt;Project 1&lt;/h2&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;Build a basic &lt;strong&gt;automatic differentiation&lt;/strong&gt; framework, then use this to re-implement the simple two-layer neural network we used for the MNIST digit classification problem in HW0.&lt;/p&gt;
&lt;p&gt;✅Implementing forward computation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;✅PowerScalar&lt;/li&gt;
&lt;li&gt;✅EWiseDiv&lt;/li&gt;
&lt;li&gt;✅DivScalar&lt;/li&gt;
&lt;li&gt;✅MatMul&lt;/li&gt;
&lt;li&gt;✅Summation&lt;/li&gt;
&lt;li&gt;✅BroadcastTo&lt;/li&gt;
&lt;li&gt;✅Reshape&lt;/li&gt;
&lt;li&gt;✅Negate&lt;/li&gt;
&lt;li&gt;✅Transpose&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;✅Implementing backward computation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;✅EWiseDiv&lt;/li&gt;
&lt;li&gt;✅DivScalar&lt;/li&gt;
&lt;li&gt;✅MatMul&lt;/li&gt;
&lt;li&gt;✅Summation&lt;/li&gt;
&lt;li&gt;✅BroadcastTo&lt;/li&gt;
&lt;li&gt;✅Reshape&lt;/li&gt;
&lt;li&gt;✅Negate&lt;/li&gt;
&lt;li&gt;✅Transpose&lt;/li&gt;
&lt;/ul&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;✅Topological sort: allow us to traverse through (forward or backward) the computation graph, computing gradients along the way&lt;/p&gt;
&lt;p&gt;✅Implementing reverse mode differentiation&lt;/p&gt;
&lt;p&gt;✅Softmax loss&lt;/p&gt;
&lt;p&gt;✅SGD for a two-layer neural network&lt;/p&gt;
&lt;h2 id=&#34;project-2&#34;&gt;Project 2&lt;/h2&gt;
&lt;p&gt;Implement a &lt;strong&gt;neural network library&lt;/strong&gt; in the needle framework.&lt;/p&gt;
&lt;p&gt;✅Implement a few different methods for weight initialization&lt;/p&gt;
&lt;p&gt;✅Implement additional modules&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;✅Linear: &lt;code&gt;needle.nn.Linear&lt;/code&gt; class&lt;/li&gt;
&lt;li&gt;✅ReLU:&lt;code&gt;needle.nn.ReLU&lt;/code&gt; class&lt;/li&gt;
&lt;li&gt;✅Sequential: &lt;code&gt;needle.nn.Sequential&lt;/code&gt; class&lt;/li&gt;
&lt;li&gt;✅LogSumExp: &lt;code&gt;needle.ops.LogSumExp&lt;/code&gt; class&lt;/li&gt;
&lt;li&gt;✅SoftmaxLoss: &lt;code&gt;needle.nn.SoftmaxLoss&lt;/code&gt; class&lt;/li&gt;
&lt;li&gt;✅LayerNorm1d: &lt;code&gt;needle.nn.LayerNorm1d&lt;/code&gt; class&lt;/li&gt;
&lt;li&gt;✅Flatten: &lt;code&gt;needle.nn.Flatten&lt;/code&gt; class&lt;/li&gt;
&lt;li&gt;✅BatchNorm1d: &lt;code&gt;needle.nn.BatchNorm1d&lt;/code&gt; class&lt;/li&gt;
&lt;li&gt;✅Dropout: &lt;code&gt;needle.nn.Dropout&lt;/code&gt; class&lt;/li&gt;
&lt;li&gt;✅Residual: &lt;code&gt;needle.nn.Residual&lt;/code&gt; class&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;✅Implement the &lt;code&gt;step&lt;/code&gt; function of the following optimizers.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;✅SGD: &lt;code&gt;needle.optim.SGD&lt;/code&gt; class&lt;/li&gt;
&lt;li&gt;✅Adam: &lt;code&gt;needle.optim.Adam&lt;/code&gt; class&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;✅Implement two data primitives: &lt;code&gt;needle.data.DataLoader&lt;/code&gt; and &lt;code&gt;needle.data.Dataset&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;✅Transformations: &lt;code&gt;RandomFlipHorizontal&lt;/code&gt; function and &lt;code&gt;RandomFlipHorizontal&lt;/code&gt; class&lt;/li&gt;
&lt;li&gt;✅Dataset: &lt;code&gt;needle.data.MNISTDataset&lt;/code&gt; class&lt;/li&gt;
&lt;li&gt;✅Dataloader: &lt;code&gt;needle.data.Dataloader&lt;/code&gt; class&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;✅Build and train an MLP ResNet&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;✅ResidualBlock: &lt;code&gt;ResidualBlock&lt;/code&gt; function&lt;/li&gt;
&lt;li&gt;✅MLPResNet: &lt;code&gt;MLPResNet&lt;/code&gt; function&lt;/li&gt;
&lt;li&gt;✅Epoch: &lt;code&gt;epoch&lt;/code&gt; function&lt;/li&gt;
&lt;li&gt;✅Train Mnist: &lt;code&gt;train_mnist&lt;/code&gt; function&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;project-3&#34;&gt;Project 3&lt;/h2&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;Build a simple backing library for the processing that underlies most deep learning systems: &lt;strong&gt;the n-dimensional array&lt;/strong&gt; (a.k.a. the NDArray).&lt;/p&gt;
&lt;p&gt;✅Python array operations&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;✅reshape: &lt;code&gt;reshape&lt;/code&gt; function&lt;/li&gt;
&lt;li&gt;✅permute: &lt;code&gt;permute&lt;/code&gt; function&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Baidu E-commerce Distributed  Order System</title>
      <link>https://0324wy.github.io/projects/baidu_e_commerce/</link>
      <pubDate>Fri, 27 Jan 2023 10:00:00 +0000</pubDate>
      <guid>https://0324wy.github.io/projects/baidu_e_commerce/</guid>
      <description>&lt;h1 id=&#34;baidu-e-commerce-middle-platform&#34;&gt;Baidu E-commerce Middle Platform&lt;/h1&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;This project is the Baidu E-commerce Middle Platform project. The role of the E-commerce Middle Platform is to provide common e-commerce capabilities for Front Platform business parties, such as ordering, after-sales, promotions, and product management.&lt;/p&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;It is divided into four small teams, including Shop Center, Commodity Center, Marketing Center, and Trading Center. The Shop Center is mainly used to manage the stores of B-side merchants. The Commodity Center is used to manage the inventory and qualifications of products. The Trading Center is used to provide services such as ordering, shopping cart ordering, after-sales, and logistics inquiry. The Marketing Center is used to provide services such as creating coupons for merchants and calculating marketing prices.&lt;/p&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;Front Platform business parties include products from different industries such as education, e-commerce, medical beauty, and life services. For example, AiQiCha is a product for the enterprise service industry, and ZhiLiaoHaoXue is a product for the education industry. Users enter the corresponding Front Platform products by clicking related links through the Baidu search engine. When users have e-commerce-related needs, they will use the services of the Middle Platform. For example, using the education industry product ZhiLiaoHaoXue to purchase an online course.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://p.ipic.vip/xmahh5.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;design-and-architecture&#34;&gt;Design and Architecture&lt;/h2&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;Taking the example of the Front Platform application DuXiaoDian calling the Trading Center, there are a total of seven modules in the entire chain, each of which is independently deployed and uses a cluster architecture. The CDN servers, reverse proxy servers, and load balancing servers sit at the top of the chain. The Trading Center connects to both distributed database servers and distributed cache servers.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://p.ipic.vip/z5bxkm.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CDN Servers&lt;/strong&gt;&lt;/p&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;CDN servers are designed to improve the availability and performance of a service by distributing it geographically closer to end-users. Essentially, a CDN is a cache server located closer to the users to speed up their access.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Reverse Proxy Servers&lt;/strong&gt;&lt;/p&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;Reverse proxy servers serve a similar function to CDN servers, but they are located on the side of the website&amp;rsquo;s data center. Additionally, they are responsible for ensuring security and acting as a barrier between the web server and external traffic.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Loading Balancing Servers&lt;/strong&gt;&lt;/p&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;Load balancing servers are positioned in front of your backend servers and are responsible for distributing client requests across a group of servers. This is done in a way that maximizes speed and capacity utilization, while also ensuring that no single server becomes overloaded and negatively impacts performance. In the event that a server goes down, the load balancer redirects traffic to the remaining online servers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Distributed Cache Servers&lt;/strong&gt;&lt;/p&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;Distributed cache servers are servers that store webpages or other internet content locally. By storing frequently accessed data in temporary storage, cache servers both speed up access to data and reduce the demand on an enterprise&amp;rsquo;s bandwidth.&lt;/p&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;In this project, we are using Redis cluster as our distributed cache servers. Redis is known for its high-performance data read and write functions, and is widely used in caching scenarios. By using Redis, we can improve the performance of our business systems and better withstand high levels of concurrent traffic requests to the database.&lt;/p&gt;
&lt;h2 id=&#34;core-question&#34;&gt;Core Question&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;How To Solve the Data Consistency Issues Between Redis And MySQL?&lt;/strong&gt;&lt;/p&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;This is also a classic problem in distributed systems - how to ensure data consistency between two heterogeneous systems.&lt;/p&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;Setting up Redis cache is to improve the performance of the system by copying hot data from MySQL to Redis. When a read request is received, it is directly read from Redis instead of from MySQL database. If the data is not available in the Redis cache, it is read from the database, and the data is then copied from the database to Redis.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://p.ipic.vip/pe646f.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;However, this can cause a problem of data inconsistency between the two systems. For example, if the data X = 1 in MySQL is modified to X = 2, the old data X = 1 will still exist in the Redis cache.&lt;/p&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;If strong consistency is guaranteed, availability will be sacrificed. When modifying MySQL data, Redis must be updated synchronously, and no other read requests can be accepted during the update.&lt;/p&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;To ensure availability, only eventual consistency can be guaranteed. In this project, a solution to ensure eventual consistency is adopted. When the data X = 1 in MySQL is modified to X = 2, MySQL generates a Binlog record of the data change, and when the Binlog is listened to, the change record is added to the message queue. The consumer side consumes this message by deleting the corresponding data from Redis. When a new request comes in, if the data is not in the Redis cache, it is read from the database and copied to Redis. This ensures eventual consistency between Redis and MySQL data.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://p.ipic.vip/ixrc06.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;Deleting the data X = 1 from Redis instead of modifying it to X = 2 is because the cached data may not be read immediately when data changes occur, so deleting the cache improves its utilization.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning Model for Wind Speed Prediction</title>
      <link>https://0324wy.github.io/projects/windspeed/</link>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://0324wy.github.io/projects/windspeed/</guid>
      <description>&lt;p style=&#34;text-align: justify;&#34;&gt;Short-term wind speed forecast is of great importance to wind farm regulation and its early warning. Previous studies mainly focused on the prediction at a single location but few extended the task to 2-D wind plane.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://p.ipic.vip/7xoehl.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;In this study, a novel deep learning model was proposed for a 2-D regional wind speed forecast, using the combination of the auto-encoder of convolutional neural network (CNN) and the long short-term memory unit (LSTM). The 12-hidden-layer deep CNN was adopted to encode the high dimensional 2-D input into the embedding vector and inversely, to decode such latent representation after it was predicted by the LSTM module based on historical data.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
